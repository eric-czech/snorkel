{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 4: Training our End Extraction Model\n",
    "\n",
    "In this final section of the tutorial, we'll use the noisy training labels we generated in the last tutorial part to train our end machine learning model.\n",
    "\n",
    "For this tutorial, we will be training a fairly effective deep learning model. More generally, however, Snorkel plugs in with many ML libraries, making it easy to use almost any state-of-the-art model as the end model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from snorkel.model.utils import MetalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Loading Candidates and Gold Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_data.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "    test_labels = pickle.load(f)\n",
    "\n",
    "with open('dev_data.pkl', 'rb') as f:\n",
    "    dev_df = pickle.load(f)\n",
    "    dev_labels = pickle.load(f)\n",
    "    \n",
    "with open('train_data.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open('train_proba.pkl', 'rb') as f:\n",
    "    train_marginals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Training a _Long Short-term Memory_ (LSTM) Neural Network\n",
    "\n",
    "[LSTMs](https://en.wikipedia.org/wiki/Long_short-term_memory) can acheive state-of-the-art performance on many text classification tasks. We'll train a simple LSTM model below. \n",
    "\n",
    "In deep learning, hyperparameter tuning is very important and computationally expensive step in training models. For purposes of this tutorial, we have a pre-trained model using the training labels generated from the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we prepare the input to our LSTM by adding *markers* to the beginning and end of the person mentions so the LSTM knows which two persons in the sentence we want to learn a relation for. We then featurize the tokens it using a standard vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "??EmbeddingFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.vocab.stoi['BEGIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import EmbeddingFeaturizer\n",
    "from utils import mark_entities\n",
    "\n",
    "markers = ['[[BEGIN0]]','[[END0]]','[[BEGIN1]]','[[END1]]']\n",
    "featurizer = EmbeddingFeaturizer(markers=markers)\n",
    "\n",
    "def convert_to_lstm_input(data):\n",
    "    X = []\n",
    "    #mark candidates with markers\n",
    "    for i in range(len(data)):\n",
    "        cand = data.loc[i]\n",
    "        marked_tokens = mark_entities(\n",
    "                    cand.tokens,\n",
    "                    positions=[cand.person1_word_idx, cand.person2_word_idx],\n",
    "                    markers=markers)\n",
    "        X.append(marked_tokens)\n",
    "        \n",
    "    #featurize string tokens tokens\n",
    "    featurize_X = featurizer.fit_transform(X)\n",
    "    return featurize_X\n",
    "\n",
    "train_X_tensor = convert_to_lstm_input(train_df)\n",
    "dev_X_tensor = convert_to_lstm_input(dev_df)\n",
    "test_X_tensor = convert_to_lstm_input(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import upgrade_dataloaders\n",
    "\n",
    "datasets = []\n",
    "datasets.append(MetalDataset(train_X_tensor, torch.LongTensor(train_marginals[:,0]))) #TODO: check \n",
    "datasets.append(MetalDataset(dev_X_tensor, torch.LongTensor(dev_labels+1.)))\n",
    "datasets.append(MetalDataset(test_X_tensor, torch.LongTensor(test_labels+1.)))\n",
    "\n",
    "dataloaders = []\n",
    "for dataset, split in zip(datasets, [\"train\", \"valid\", \"test\"]):\n",
    "    dataloader = DataLoader(dataset)\n",
    "    dataloader.split = split\n",
    "    dataloaders.append(dataloader)\n",
    "    \n",
    "dataloaders = upgrade_dataloaders(dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LSTM Model\n",
    "For purposes of this tutorial, we have saved a pre-trained model that was trained using probabilistic labels generated in the previous notebook. \n",
    "\n",
    "We define our model here and load the pretrained weights before evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(name=SimpleModel)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from snorkel.mtl.simple_model import SimpleModel\n",
    "from utils import LSTMModule, EmbeddingsEncoder\n",
    "\n",
    "MAX_INT = train_X_tensor.max()\n",
    "embed_size = 4\n",
    "hidden_size = 5\n",
    "\n",
    "lstm_module = LSTMModule(\n",
    "    embed_size,\n",
    "    hidden_size,\n",
    "    bidirectional=False,\n",
    "    verbose=False,\n",
    "    lstm_reduction=\"attention\",\n",
    "    encoder_class=EmbeddingsEncoder,\n",
    "    encoder_kwargs={\"vocab_size\": MAX_INT + 1},\n",
    ")\n",
    "\n",
    "model = SimpleModel(\n",
    "    modules=[\n",
    "    lstm_module,\n",
    "    nn.Linear(lstm_module.output_dim,1)],\n",
    "    metrics = ['accuracy', 'f1', 'precision','recall'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and Score Pre-Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Set Scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-5c059f928774>\", line 4, in <module>\n",
      "    scores = model.score(dataloaders[1])\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 43, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/snorkel/mtl/model.py\", line 279, in score\n",
      "    results = self.predict(dataloader, return_preds=True)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 43, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/snorkel/mtl/model.py\", line 232, in predict\n",
      "    X_batch_dict, dataloader.task_to_label_dict.keys()\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 43, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/snorkel/mtl/model.py\", line 214, in _calculate_probs\n",
      "    outputs = self.forward(X_dict, task_names)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/snorkel/mtl/model.py\", line 140, in forward\n",
      "    output = self.module_pool[operation.module_name].forward(*input)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 140, in forward\n",
      "    return self.module(*inputs, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/eczech/repos/misc/python/snorkel/tutorials/workshop/utils.py\", line 271, in forward\n",
      "    outputs, (h_t, c_t) = self.lstm(X_packed)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/rnn.py\", line 557, in forward\n",
      "    return self.forward_packed(input, hx)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/rnn.py\", line 550, in forward_packed\n",
      "    output, hidden = self.forward_impl(input, hx, batch_sizes, max_batch_size, sorted_indices)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/torch/nn/modules/rnn.py\", line 525, in forward_impl\n",
      "    self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/eczech/anaconda3/envs/snorkel-v2/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.load('./trained_spouse_model')\n",
    "\n",
    "print(\"Dev Set Scores\")\n",
    "scores = model.score(dataloaders[1])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This takes > 30 mins to Run on a CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train SimpleModel\n",
    "# from snorkel.mtl.trainer import Trainer\n",
    "# trainer = Trainer(progress_bar=True, n_epochs=5)\n",
    "# trainer.train_model(model, dataloaders)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
