{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 3: Training the Label Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Loading Data\n",
    "\n",
    "First we'll load our label matrices from notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dev_data.pkl', 'rb') as f:\n",
    "    dev_df = pickle.load(f)\n",
    "    dev_labels = pickle.load(f)\n",
    "    \n",
    "with open('train_data.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open('dev_L.pkl', 'rb') as f:\n",
    "    dev_L = pickle.load(f)\n",
    "    \n",
    "with open('train_L.pkl', 'rb') as f:\n",
    "    train_L = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II: Unifying supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Model\n",
    "We know that our labeling functions will not be perfect, and some may be quite low-quality, so we will _model_ their accuracies with a factor-graph based label model, which Snorkel will help us easily apply.\n",
    "\n",
    "This will ultimately produce a single set of **noise-aware training labels**, which are probabilistic or confidence-weighted labels. We will then use these labels to train an end extraction model in the next notebook.  For more technical details of this overall approach, see our [NeurIPS 2016](https://arxiv.org/abs/1605.07723) and [AAAI 2019](https://arxiv.org/abs/1810.02840) papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training the Model\n",
    "When training the generative model, we'll tune our hyperparamters using a simple grid search. We use `plusminus_to_categorical` to map our labeling convention from `{0,-1,1}` in the previous notebook to `{0,1,2}` as the multiclass convention in this notebook for the `LabelModel`. \n",
    "\n",
    "**Parameter Definitions**\n",
    "\n",
    "    k  Cardinality, or the number of classes in the task\n",
    "    lr  The factor by which we update model weights after computing the gradient\n",
    "    class_balance Proportion of [positive, negative] samples in the dataset\n",
    "    n_epochs     A single pass through all the data in your training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[500 epo]: TRAIN:[loss=0.001]\n",
      "[1000 epo]: TRAIN:[loss=0.001]\n",
      "[1500 epo]: TRAIN:[loss=0.001]\n",
      "[2000 epo]: TRAIN:[loss=0.001]\n",
      "[2500 epo]: TRAIN:[loss=0.001]\n",
      "[3000 epo]: TRAIN:[loss=0.001]\n",
      "[3500 epo]: TRAIN:[loss=0.001]\n",
      "[4000 epo]: TRAIN:[loss=0.001]\n",
      "[4500 epo]: TRAIN:[loss=0.001]\n",
      "[5000 epo]: TRAIN:[loss=0.001]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model.baselines import MajorityLabelVoter\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "from snorkel.model.utils import plusminus_to_categorical\n",
    "\n",
    "label_model = LabelModel(k=2, verbose=True, seed=123)\n",
    "label_model.train_model(\n",
    "            plusminus_to_categorical(train_L.toarray()),\n",
    "            lr = 1e-1,\n",
    "            class_balance=[0.2,0.8],\n",
    "            n_epochs=5000,\n",
    "            log_train_every=500,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Model Metrics\n",
    "These are the weights learned for each LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2513\n",
       " 1     190\n",
       " 0     108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dev_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    0.893988\n",
       " 1    0.067592\n",
       " 0    0.038420\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dev_labels).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n",
      "F1: 0.431\n",
      "Precision: 0.373\n",
      "Recall: 0.511\n",
      "        y=1    y=2   \n",
      " l=1    97     163   \n",
      " l=2    93    2350   \n"
     ]
    }
   ],
   "source": [
    "score = label_model.score((plusminus_to_categorical(dev_L.toarray()), \n",
    "                           plusminus_to_categorical(dev_labels)), \n",
    "                          metric=['accuracy','f1', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote Comparison\n",
    "We can also compare the performance of the LabelModel to computing a majority vote across all the LFs. In case of ties, we guess `2`, which means there is no spouse relationship. This is a common assumption in the information extraction literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.814\n",
      "F1: 0.306\n",
      "Precision: 0.207\n",
      "Recall: 0.584\n",
      "        y=1    y=2   \n",
      " l=1    111    425   \n",
      " l=2    79    2088   \n"
     ]
    }
   ],
   "source": [
    "mv_model = MajorityLabelVoter(k=2, verbose=True)\n",
    "mv_model.train_model(\n",
    "            plusminus_to_categorical(train_L.toarray()),\n",
    "        )\n",
    "\n",
    "score = mv_model.score((plusminus_to_categorical(dev_L.toarray()), \n",
    "                           plusminus_to_categorical(dev_labels)), \n",
    "                          metric=['accuracy','f1', 'precision', 'recall'], break_ties=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we break ties randomly, we get a lower F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.451\n",
      "F1: 0.162\n",
      "Precision: 0.091\n",
      "Recall: 0.758\n",
      "        y=1    y=2   \n",
      " l=1    144   1439   \n",
      " l=2    46    1074   \n"
     ]
    }
   ],
   "source": [
    "score = mv_model.score((plusminus_to_categorical(dev_L.toarray()), \n",
    "                           plusminus_to_categorical(dev_labels)), \n",
    "                          metric=['accuracy','f1', 'precision', 'recall'], break_ties=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Probabilistic Labels\n",
    "One immediate santity check  you can peform using the generative model is to visually examine the distribution of predicted training probabilistic labels. Ideally, there should get a bimodal distribution with large seperation between each peaks, as shown below by the far right image. The corresponds to good signal for true and positive class labels. For your first Snorkel application, you'll probably see probabilistic labels closer to the far left or middle images. With all mass centered around p=0.5, as shown on the **left**, you probably need to write more LFs got get more overall _coverage_. In the **right** image, you have good negative coverage, but not enough positive LFs\n",
    "\n",
    "<img align=\"left\" src=\"imgs/marginals-common.jpg\" width=\"265px\" style=\"margin-right:0px\">\n",
    "\n",
    "<img align=\"center\" src=\"imgs/marginals-real.jpg\" width=\"265px\" style=\"margin-right:0px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_proba = label_model.predict_proba(plusminus_to_categorical(train_L.toarray()))\n",
    "plt.hist(train_proba[:,0], bins=20, range=(0.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our training labels\n",
    "\n",
    "Finally, we'll save the `train_proba`, which are our **\"noise-aware training labels\"**, so that we can use them to train a downstream machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_proba = label_model.predict_proba(plusminus_to_categorical(dev_L.toarray()))\n",
    "with open('dev_proba.pkl', 'wb') as f:\n",
    "    pickle.dump(dev_proba, f)\n",
    "    \n",
    "with open('train_proba.pkl', 'wb') as f:\n",
    "    pickle.dump(train_proba, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
