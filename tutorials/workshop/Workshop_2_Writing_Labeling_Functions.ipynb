{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 2: Writing  Labeling Functions\n",
    "\n",
    "In Snorkel, our primary interface through which we provide training signal to the end extraction model we are training is by writing **labeling functions (LFs)** (as opposed to hand-labeling massive training sets).  We'll go through some examples for our spouse classification task below.\n",
    "\n",
    "A labeling function is a Python function that accepts a candidate, or a row of the DataFrame, as the input argument and outputs a label for the candidate. For ease of exposition in this notebook, we return `1` if it says the pair of persons in the candidate were married at some point,  `-1` if the pair of persons in the candidate were never married, and `0` if it doesn't know how to vote and abstains. In practice, many labeling functions are often unipolar: it labels only `1`s and `0`s, or it labels only `-1`s and `0`s.\n",
    "\n",
    "(Note we will change our mapping to use `2` to represent the absence of a relationship to match the multiclass convention in the next notebook for the `LabelModel`. This does not affect this notebook.)\n",
    "\n",
    "Recall that our goal is to ultimately train a high-performance classification model that predicts which of our candidates are true spouse relations. It turns out that we can do this by writing potentially low-quality labeling functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  I. Background\n",
    "\n",
    "### Preprocessing the Database\n",
    "\n",
    "In a real application, there is a lot of data preparation, parsing, and database loading that needs to be completed before we dive into writing labeling functions. Here we've pre-generated candidates in a pandas DataFrame object per split (train,dev,test).\n",
    "\n",
    "###  Using a _Development Set_ of Human-labeled Data\n",
    "\n",
    "In our setting, we will use the phrase _development set_ to refer to a set of examples (here, a subset of our training set) which we label by hand and use to help us develop and refine labeling functions.  Unlike the _test set_, which we do not look at and use for final evaluation, we can inspect the development set while writing labeling functions. This is a list of `{-1,1}` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dev_data.pkl', 'rb') as f:\n",
    "    dev_df = pickle.load(f)\n",
    "    dev_labels = pickle.load(f)\n",
    "    \n",
    "with open('train_data.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Helpers\n",
    "\n",
    "When writing labeling functions, there are several operators you will use over and over again. In the case of text relation extraction as with this task, common operators include fetching text between mentions of the two people in a candidate, examing word windows around person mentions, etc. Note that other domains and tasks, the required preprocessors will be different. \n",
    "\n",
    "We provide several helper functions in `spouse_preprocessors`:  these are Python helper functions that you can apply to candidates in the DataFrame to return objects that are helpful during LF development. You can (and should!) write your own helper functions to help write LFs.\n",
    "\n",
    "We provide an example of a preprocessor definition here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.preprocess import Preprocessor, PreprocessorMode, preprocessor\n",
    "\n",
    "@preprocessor\n",
    "def get_text_between(cand):\n",
    "    \"\"\"\n",
    "    Returns the text between the two person mentions in the sentence for a candidate\n",
    "    \"\"\"\n",
    "    start = cand.person1_word_idx[1] + 1\n",
    "    end = cand.person2_word_idx[0]\n",
    "    cand.text_between = ' '.join(cand.tokens[start:end])\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate PreProcessors\n",
    "\n",
    "We provide a set of helper functions for this task in `spouse_preprocessors.py` that take as input a candidate, or row of a DataFrame in our case. For the purpose of the tutorial, we have two of these fields preprocessed in the data, which can be used when creating labeling functions.\n",
    "\n",
    "`get_between_tokens(cand)`\n",
    "\n",
    "`get_left_tokens(cand)`\n",
    "\n",
    "`get_right_tokens(cand)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Labeling Functions\n",
    "\n",
    "## A. Pattern Matching Labeling Functions\n",
    "\n",
    "One powerful form of labeling function design is defining sets of keywords or regular expressions that, as a human labeler, you know are correlated with the true label. For example, we could define a dictionary of terms that occur between person names in a candidate. One simple dictionary of terms indicating a true relation could be, which we could use in a labeling function like shown below:\n",
    "    \n",
    "    spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "\n",
    " \n",
    "    @labeling_function(resources=dict(spouses=spouses), preprocessors=[get_left_tokens])\n",
    "    def LF_husband_wife_left_window(x, spouses):\n",
    "        if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "            return POS\n",
    "        elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "            return POS\n",
    "        else:\n",
    "            return ABSTAIN\n",
    "\n",
    "**Note that:**\n",
    "1. To access the text between the person mentions, we can use the **`get_left_tokens` preprocessor!**\n",
    "2. We use **resources like the spouses dictionary** to encode themes/categories of relationships!\n",
    "\n",
    "There are a few advantages of having preprocessors and labeling functions in this form: \n",
    "\n",
    "**Data Agnostic:**  Operate over multiple data types without rewriting\n",
    "    \n",
    "**Incremental Processing:** Can create preprocessors as needed while writing LFs!\n",
    "     \n",
    "**Future Use:** Can store them for later for different tasks since they are reproducible and modular\n",
    "     \n",
    "**Optimizations:** Allows caching behind-the-scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.types import DataPoint\n",
    "\n",
    "from spouse_preprocessors import get_left_tokens, get_person_last_names, get_person_text\n",
    "\n",
    "POS = 1\n",
    "NEG = -1 \n",
    "ABSTAIN = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.apply import lf_applier_pandas\n",
    "#!cat ~/anaconda3/envs/snorkel-v2/lib/python3.6/site-packages/snorkel/labeling/apply/lf_applier_pandas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the `spouse` words appearing between the person mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "@labeling_function(resources=dict(spouses=spouses))\n",
    "def LF_husband_wife(x, spouses):\n",
    "    return POS if len(spouses.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the `spouse` words appearing to the left of the person mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(resources=dict(spouses=spouses), preprocessors=[get_left_tokens])\n",
    "def LF_husband_wife_left_window(x, spouses):\n",
    "    if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return POS\n",
    "    elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return POS\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the person mentions having the same last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def LF_same_last_name(x):\n",
    "    p1_ln, p2_ln = get_person_last_names(x)\n",
    "    \n",
    "    if p1_ln and p2_ln and p1_ln == p2_ln:\n",
    "        return POS\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the words `and ... married` between person mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def LF_and_married(x):\n",
    "    return POS if 'and' in x.between_tokens and 'married' in x.person2_right_tokens else ABSTAIN    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for words that refer to `family` relationships between and to the left of the person mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "family = ['father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin']\n",
    "family = set(family+[f + '-in-law' for f in family])\n",
    "\n",
    "@labeling_function(resources=dict(family=family))\n",
    "def LF_familial_relationship(x, family):\n",
    "    return POS if len(family.intersection(set(x.between_tokens))) > 0 else ABSTAIN  \n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(family=family), preprocessors=[get_left_tokens])\n",
    "def LF_family_left_window(x, family):\n",
    "    if len(set(family).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return NEG\n",
    "    elif len(set(family).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return NEG\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for `other` relationship words between person mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "@labeling_function(resources=dict(other=other))\n",
    "def LF_other_relationship(x, other):\n",
    "    return NEG if len(other.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Labeling Functions to the Data\n",
    "We create a list of labeling functions and apply them to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "??PandasLFApplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2811/2811 [00:03<00:00, 837.05it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier([LF_husband_wife,\n",
    "                           LF_husband_wife_left_window,\n",
    "                           LF_same_last_name,\n",
    "                           LF_and_married, \n",
    "                           LF_familial_relationship,\n",
    "                           LF_family_left_window,\n",
    "                           LF_other_relationship])\n",
    "L = applier.apply(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Metrics\n",
    "\n",
    "#### Coverage\n",
    "One simple metric we can compute quickly is our _coverage_, the number of candidates labeled by our LF, on our training set (or any other set).\n",
    "\n",
    "#### Precision / Recall / F1\n",
    "If we have gold labeled data, we can also compute standard precision, recall, and F1 metrics for the output of a single labeling function. These metrics are computed over 4 _error buckets_: _True Positives_ (tp), _False Positives_ (fp), _True Negatives_ (tn), and _False Negatives_ (fn).\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{tp}{(tp + fp)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "recall = \\frac{tp}{(tp + fn)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 = 2 \\cdot \\frac{ (precision \\cdot recall)}{(precision + recall)}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Viewing Performance Metrics\n",
    "If we have gold labeled data, we can evaluate formal metrics. Below, we'll compute our empirical scores using human-labeled development set data and then look at performance metrics for `LF_husband_wife` LF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF_husband_wife coverage: \t 0.08964781216648879\n",
      "LF_husband_wife F1 score:  \t 0.4208144796380091\n",
      "LF_husband_wife precision:  \t 0.36904761904761907\n",
      "LF_husband_wife recall:  \t 0.48947368421052634\n"
     ]
    }
   ],
   "source": [
    "from snorkel.model.metrics import coverage_score, f1_score, precision_score, recall_score\n",
    "\n",
    "print(\"LF_husband_wife coverage: \\t\", coverage_score(dev_labels,L[:,0]))\n",
    "print(\"LF_husband_wife F1 score:  \\t\", f1_score(dev_labels,L[:,0]))\n",
    "print(\"LF_husband_wife precision:  \\t\", precision_score(dev_labels,L[:,0]))\n",
    "print(\"LF_husband_wife recall:  \\t\", recall_score(dev_labels,L[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Distant Supervision Labeling Functions\n",
    "\n",
    "In addition to using factories that encode pattern matching heuristics, we can also write labeling functions that _distantly supervise_ examples. Here, we'll load in a list of known spouse pairs and check to see if the pair of persons in a candidate matches one of these.\n",
    "\n",
    "**DBpedia**\n",
    "http://wiki.dbpedia.org/\n",
    "Our database of known spouses comes from DBpedia, which is a community-driven resource similar to Wikipedia but for curating structured data. We'll use a preprocessed snapshot as our knowledge base for all labeling function development.\n",
    "\n",
    "We can look at some of the example entries from DBPedia and use them in a simple distant supervision labeling function.\n",
    "\n",
    "Make sure `dbpedia.pkl` is in the `tutorials/workshop/` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Duke George', 'Grand Duchess Catherine Pavlovna'),\n",
       " ('Helen Milliken', 'William Milliken'),\n",
       " ('Alexander', 'Aspasia Manos'),\n",
       " ('Brooke Shields', 'Chris Henchy'),\n",
       " ('Bronwyn Bancroft', 'Ned Manning')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('dbpedia.pkl', 'rb') as f:\n",
    "     known_spouses = pickle.load(f)\n",
    "        \n",
    "list(known_spouses)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "??labeling_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(resources=dict(known_spouses=known_spouses))\n",
    "def LF_distant_supervision(x: DataPoint, known_spouses: List[str]) -> int:\n",
    "    p1, p2 = get_person_text(x)\n",
    "    return POS if (p1, p2) in known_spouses or (p2, p1) in known_spouses else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None \n",
    "\n",
    "# Last name pairs for known spouses\n",
    "last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "\n",
    "@labeling_function(resources=dict(last_names=last_names))\n",
    "def LF_distant_supervision_last_names(x: DataPoint, last_names: List[str]) -> int:\n",
    "    p1_ln, p2_ln = get_person_last_names(x)\n",
    "    \n",
    "    return POS if (p1_ln != p2_ln) and ((p1_ln, p2_ln) in last_names or (p2_ln, p1_ln) in last_names) else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time you write a new labeling function, add it to appliers and make sure to include it in the new L matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [LF_husband_wife,\n",
    "                           LF_husband_wife_left_window,\n",
    "                           LF_same_last_name,\n",
    "                           LF_and_married, \n",
    "                           LF_familial_relationship,\n",
    "                           LF_family_left_window,\n",
    "                           LF_other_relationship,\n",
    "                           LF_distant_supervision,\n",
    "                           LF_distant_supervision_last_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "def corrupt(fn):\n",
    "    def fnx(x):\n",
    "        do_abstain = np.random.rand(1)[0] > .5\n",
    "        do_rand = np.random.rand(1)[0] > .5\n",
    "        if do_abstain:\n",
    "            return 0\n",
    "        if do_rand:\n",
    "            return np.random.choice([-1, 1], size=1)[0]\n",
    "        return fn(x)\n",
    "corrupted_fns = [corrupt(fn) for fn in fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(fns)\n",
    "#applier = PandasLFApplier(corrupted_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2811/2811 [00:04<00:00, 666.02it/s]\n",
      "100%|██████████| 22254/22254 [00:28<00:00, 774.04it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_L = applier.apply(dev_df)\n",
    "with open('dev_L.pkl', 'wb') as f:\n",
    "    pickle.dump(dev_L, f)\n",
    "    \n",
    "train_L = applier.apply(train_df)\n",
    "with open('train_L.pkl', 'wb') as f:\n",
    "    pickle.dump(train_L, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2811,), (2811, 9))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dev_data.pkl', 'rb') as f:\n",
    "    dev_df = pickle.load(f)\n",
    "    dev_labels = pickle.load(f)\n",
    "    \n",
    "dev_labels.shape, dev_L.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_L.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Writing Custom Labeling Functions\n",
    "\n",
    "The strength of LFs is that you can write any arbitrary function and use it to supervise a classification task. This approach can combine many of the same strategies discussed above or encode other information. \n",
    "\n",
    "For example, we observe that when mentions of person names occur far apart in a sentence, this is a good indicator that the candidate's label is False. You can write a labeling function that uses preprocessor `get_text_between` or the existing field `get_between_tokens` to write such an LF!\n",
    "\n",
    "\n",
    "    \n",
    "**IMPORTANT** Good labeling functions manage a trade-off between high coverage and high precision. When constructing your dictionaries, think about building larger, noiser sets of terms instead of relying on 1 or 2 keywords. Sometimes a single word can be very predictive (e.g., `ex-wife`) but it's almost always better to define something more general, such as a regular expression pattern capturing _any_ string with the `ex-` prefix. \n",
    "\n",
    "**Try editing and running the cells below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @labeling_function()\n",
    "# def LF_new(x: DataPoint) -> int:\n",
    "#     return POS if x.person1_word_idx[0] > 3 else ABSTAIN #TODO: Change this!\n",
    "\n",
    "# applier = PandasLFApplier([LF_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dev_L = applier.apply(dev_df)\n",
    "# sp.hstack((dev_L, new_dev_L), format='csr')\n",
    "# with open('dev_L.pkl', 'wb') as f:\n",
    "#     pickle.dump(dev_L, f)\n",
    "    \n",
    "# new_train_L = applier.apply(train_df)\n",
    "# sp.hstack((train_L, new_train_L), format='csr')\n",
    "# with open('train_L.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_L, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-butt": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
